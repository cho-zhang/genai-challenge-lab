from dataclasses import dataclass
from enum import StrEnum
from typing import Any, Literal


@dataclass
class LLMConfig:
    model_name: str
    max_completion_tokens: int | None = None
    reasoning_effort: str | None = None
    temperature: float | None = None
    top_p: float | None = None
    tool_choice: str | None = None


@dataclass
class TextContent:
    text: str
    type: Literal["text"] = "text"


@dataclass
class ImageUrlContent:
    """Image input: https://platform.openai.com/docs/api-reference/chat/create"""

    image_url: str  # URL of the image or the base64 encoded image data
    type: Literal["image_url"] = "image_url"


MESSAGE_CONTENT = TextContent | ImageUrlContent


class MessageRole(StrEnum):
    """The role of the message's author. Roles can be: system, user, assistant, function or tool."""

    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"
    TOOL = "tool"


@dataclass
class ToolCallInfo:
    """Function tool call.

    Example:
    "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_current_weather",
              "arguments": "{\n\"location\": \"Boston, MA\"\n}"
            }
          }
        ]
    }
    """

    id: str
    tool_name: str
    tool_arguments: dict[str, Any]


class BaseMessage:
    """
    Base messages in /completions API.
    Favor data type over unbounded messages: list[dict[str, str]].

    // text
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]

    // image
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What is in this image?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
            }
          }
        ]
      }
    ]
    """

    content: str | list[MESSAGE_CONTENT]


@dataclass
class SystemMessage(BaseMessage):
    content: str
    role: Literal[MessageRole.SYSTEM] = MessageRole.SYSTEM


@dataclass
class UserMessage(BaseMessage):
    content: str | list[MESSAGE_CONTENT]
    role: Literal[MessageRole.USER] = MessageRole.USER


@dataclass
class AssistantMessage(BaseMessage):
    """Assistant message could be either str content or tool calls generated by the model."""

    content: str | None = None
    tool_calls: list[ToolCallInfo] | None = None
    debug_llm_input: dict[str, Any] | None = None
    debug_llm_output: dict[str, Any] | None = None
    role: Literal[MessageRole.ASSISTANT] = MessageRole.ASSISTANT


@dataclass
class ToolMessage(BaseMessage):
    """
    Tool message.

    Example: https://docs.litellm.ai/docs/completion/function_call#full-code---parallel-function-calling-with-gpt-35-turbo-1106
      messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "name": function_name,
        "content": function_response,
      })
    """

    tool_call_id: str
    tool_name: str
    content: str  # tool response
    role: Literal[MessageRole.TOOL] = MessageRole.TOOL


RoleMessage = SystemMessage | UserMessage | AssistantMessage | ToolMessage
